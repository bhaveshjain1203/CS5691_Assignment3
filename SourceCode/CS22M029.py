# -*- coding: utf-8 -*-
"""ass3new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LUoNETEjJJum3UVOzOR64_tRxfVG71DC
"""

#upload the file
import numpy as np # LA
import pandas as pd 
import io
import nltk
from nltk.corpus import words
nltk.download("words")
import matplotlib.pyplot as plt
import ast
from google.colab import files 
uploaded = files.upload()
# reading the train data
data = pd.read_csv('emails.csv')
# data.shape

#BUILDING OF DICTIONARY FROM THE GIVEN MAILS

dictionary={}
#taking the set of correct words in grammar as expression
valid = set(words.words())
totalemails=data.shape[0]
for email_i in range(totalemails):
   this_email = data.iloc[email_i, :][0].split()
   idx = len(dictionary)
   for exp in this_email:
     # check that if this word is valid and not in our dictionary then add it to dictionary
        if exp.lower() not in dictionary and exp.lower() in valid:
            dictionary[exp] = idx
            idx += 1
# print(dictionary)
dimension= len(dictionary)


#CONVERT ALL THE TRAINING MAILS INTO VECTORS 
#(which denotes the number of occurence of each word from the dictionary)
y = np.zeros((totalemails))
for email_i in range(totalemails):
  y[email_i]=data.iloc[email_i, :][1]

X = np.zeros((totalemails, dimension))
for email_i in range(totalemails):
   this_email = data.iloc[email_i, :][0].split()  
   for exp in this_email:
     #we will check that if this word is in our dictionary then it contributes to the vector
        if exp.lower() in dictionary: 
            X[email_i, dictionary[exp]] += 1

#CALCULATE THE PRIOR            
#p_hat (denotes the prior for spam mails)= number of emails that are spam/ total number of mails
spamnum=0
nonspamnum=0
for email_i in range(totalemails):
  if y[email_i]==1:
    spamnum+=1
  else:
    nonspamnum+=1
# print(spamnum)
# print(nonspamnum)
# print(totalemails)

p_hat=spamnum/totalemails


#CALCULATE THE LIKELIHOOD FOR ALL THE WORDS IN DICTIONARY
#compute the probability of each element when the mail was spam =1 in dict_spam or if it was non spam then add in dict_nonspam
dict_spam = np.zeros(dimension)
dict_nonspam=  np.zeros(dimension)

for email_i in range(totalemails):
   if y[email_i]==1:
     dict_spam+=X[email_i,]
   else :
    dict_nonspam+=X[email_i,]

probdict_spam=dict_spam/spamnum
probdict_nonspam=dict_nonspam/nonspamnum


#NAIVE BAYES SPAM CLASSIFIER
def NaiveBayes(email):
  probspamforemail=p_hat
  probnonspamforemail=(1-p_hat)
  for exp in email:
     #we will check that if this word is in our dictionary
     #POSTERIOR CALCULATION
     if  exp.lower()  in dictionary:
          if  probdict_spam[dictionary[exp]]>0:
            probspamforemail*=probdict_spam[ dictionary[exp]]
          if  probdict_nonspam[dictionary[exp]]>0:
            probnonspamforemail*=probdict_nonspam[ dictionary[exp]]
  #print("p of SPAM",probspamforemail)
  #print("p of HAM",probnonspamforemail)

  if (probspamforemail>probnonspamforemail):
    return 1
  else: 
    return 0

#READING EMAILS FROM A TEST FOLDER AND CONVERTING THEM INTO A CSV FILE
import os
import csv
examine = []
a = os.getcwd()
b=a
a = a+"/test"
os.chdir(a)

def takeinput(fp):
    with open(fp, 'r') as f:
        examine.append([f.read()])

for file in os.listdir():
    if file.endswith(".txt"):
        fp = f"{a}/{file}"
        takeinput(fp)
os.chdir(b)

filename = "test.csv"

with open(filename,'w') as csvfile:
    csvwriter = csv.writer(csvfile) 
    csvwriter.writerows(examine)


testdata = pd.read_csv('test.csv',header=None,index_col=False)
testdataArray = testdata.to_numpy()
x_test=testdataArray[:,0]
m_test = len(testdataArray)
label=[]
for i in range(m_test):
  obj=x_test[i].split()
  res=NaiveBayes(obj)
  label.append(res)
#final answer to be printed by label
print(label)

